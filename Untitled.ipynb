{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import *\n",
    "from time import sleep\n",
    "\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieveAdInfo:\n",
    "\n",
    "    def __init__(self, keyword, location=None, page=1):\n",
    "        self.url = 'https://www.gumtree.co.za/s-land-plots-for-sale/agriculture+land+for+sale/page-2/v1c9137q0p2'\n",
    "        self.search_arg = 'search?'\n",
    "        self.keyword = str(keyword)\n",
    "        self.location = str(location)\n",
    "        self.page = page\n",
    "        self.complete_url = {'search_category':'all','search_location':self.location,'q':self.keyword, 'page':self.page}\n",
    "        self.encoded_url = self.url + self.search_arg + urllib.parse.urlencode(self.complete_url)\n",
    "        \n",
    "    def get_search_url(self):\n",
    "        return self.encoded_url\n",
    "\n",
    "    def retrieve_ad_url(self, items):\n",
    "        self.remove_unnecesary(items)\n",
    "\n",
    "        ad_links = []\n",
    "        for item in items:\n",
    "            ad_links.append(self.url + urllib.parse.quote(item.get('href')))\n",
    "        return ad_links\n",
    "\n",
    "    def remove_unnecesary(self, list_):\n",
    "            for _ in range(3):\n",
    "                del list_[0]\n",
    "\n",
    "    def retrieve_multiple_pages(self):\n",
    "\n",
    "        multiple_urls = []\n",
    "\n",
    "        for i in range(1, self.page + 1):\n",
    "\n",
    "            self.__init__(self.keyword, self.location, page=i)\n",
    "            multiple_urls.append(self.get_search_url())\n",
    "\n",
    "        return multiple_urls\n",
    "\n",
    "    def retrieve_ad_title(self, items):\n",
    "\n",
    "        self.remove_unnecesary(items)\n",
    "\n",
    "        title_text = []\n",
    "        for item in items:\n",
    "            title_text.append(item.text)\n",
    "            \n",
    "            \n",
    "def main(user_input_search_entry, user_input_location_entry, user_input_num_pages_entry, user_input_filename_entry):\n",
    "\n",
    "    driver = webdriver.Chrome()\n",
    "    name_for_all_pages = []\n",
    "    links_to_be_removed = []\n",
    "\n",
    "    def multi_to_single_list(items):\n",
    "\n",
    "        one_list = []\n",
    "\n",
    "        for i in items:\n",
    "            for j in i:\n",
    "                one_list.append(j)\n",
    "\n",
    "        return one_list\n",
    "\n",
    "    def remove_falsy(items):\n",
    "\n",
    "        for single_item in items:\n",
    "            if not bool(single_item.text):\n",
    "                continue\n",
    "            else:\n",
    "                return single_item.text\n",
    "\n",
    "    def get_ad_details(all_urls):\n",
    "\n",
    "        \"\"\"Gets phone number and name from the add\"\"\"\n",
    "\n",
    "        counts_of_completed = 0\n",
    "        phone_numbers_for_all_pages = []\n",
    "        title_names_for_all_pages = []\n",
    "        \n",
    "        # Open all the connections to the ad detail page\n",
    "\n",
    "        for singleUrl in all_urls:\n",
    "            driver.get(singleUrl)\n",
    "            \n",
    "            page_html_ad_detail = urlopen(singleUrl)\n",
    "            soup_ad_detail = BeautifulSoup(page_html_ad_detail, \"html.parser\")\n",
    "            \n",
    "            counts_of_completed += 1\n",
    "            percent_completed = str(round((counts_of_completed / ad_links_count) * 100))\n",
    "            print(str(counts_of_completed) + '/' + str(ad_links_count) + ' ({}%) Completed'.format(percent_completed))\n",
    "            \n",
    "            # Retrieval of name and phone number from ad page\n",
    "            try:\n",
    "                driver.execute_script(\"document.getElementById('reply-panel-reveal-btn').click()\")\n",
    "                sleep(2)\n",
    "                phone_number_for_single_ad = remove_falsy(driver.find_elements_by_css_selector('.form-row-label'))\n",
    "\n",
    "                contact_name = soup_ad_detail.find(\"h2\", {\"class\": \"truncate-line space-mbn\"}).text.replace('\\n', '')\n",
    "\n",
    "            except WebDriverException:\n",
    "                # No phone number has been found\n",
    "                links_to_be_removed.append(driver.current_url)\n",
    "                print(\"Skipped!\\n\")\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "\n",
    "                name_for_all_pages.append(contact_name)\n",
    "                title_names_for_all_pages.append(driver.title.split('|')[0].strip())\n",
    "\n",
    "                if phone_number_for_single_ad.startswith(\"07\") or phone_number_for_single_ad.startswith(\"447\"):\n",
    "\n",
    "                            phone_numbers_for_all_pages.append(phone_number_for_single_ad)\n",
    "\n",
    "            ####\n",
    "            \n",
    "            return name_for_all_pages, phone_numbers_for_all_pages, links_to_be_removed, title_names_for_all_pages\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-887edab052e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#search_url = RetrieveAdInfo(user_input_search_entry,user_input_location_entry, user_input_num_pages_entry)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0murls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_url\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve_multiple_pages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mu_request\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpage_html\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'search_url' is not defined"
     ]
    }
   ],
   "source": [
    "#search_url = RetrieveAdInfo(user_input_search_entry,user_input_location_entry, user_input_num_pages_entry)\n",
    "\n",
    "urls = search_url.retrieve_multiple_pages()\n",
    "u_request = []\n",
    "page_html = []\n",
    "page_soup = []\n",
    "ad_links_for_all_pages = []\n",
    "\n",
    "for url in urls:\n",
    "    u_request.append(urlopen(url))\n",
    "\n",
    "    \n",
    "for a in range(len(u_request)):\n",
    "    page_html.append(u_request[a].read())\n",
    "\n",
    "# Get page_soup for multiple pages\n",
    "for b in range(len(page_html)):\n",
    "    page_soup.append(BeautifulSoup(page_html[b], \"html.parser\"))\n",
    "    \n",
    "    \n",
    "# Get Ad URL\n",
    "for c in range(len(page_soup)):\n",
    "    containers_for_all_pages = page_soup[c].findAll(\"a\", {\"class\":\"listing-link\"})\n",
    "    ad_links_for_all_pages.append(search_url.retrieve_ad_url(containers_for_all_pages))\n",
    "    \n",
    "    \n",
    "    if user_input_num_pages_entry > 1:\n",
    "        ad_links_for_all_pages = multi_to_single_list(ad_links_for_all_pages)\n",
    "    else:\n",
    "    # It is assigned the first element since it has a multi-dimensional array\n",
    "        ad_links_for_all_pages = ad_links_for_all_pages[0]\n",
    "\n",
    "        ad_links_count = len(ad_links_for_all_pages)\n",
    "        print(\"\\n\" + str(ad_links_count), \"Ad(s) have/has been found\\n\")\n",
    "\n",
    "name_for_all_pages, phone_number_for_all_pages, links_to_be_removed,title_ad_for_all_pages = get_ad_details(ad_links_for_all_pages)\n",
    "    \n",
    "    \n",
    "# Remove links that are not in list: links_to_be_removed\n",
    "\n",
    "ad_links_to_be_kept = []\n",
    "for item in ad_links_for_all_pages:\n",
    "    if item not in links_to_be_removed:\n",
    "        ad_links_to_be_kept.append(item)\n",
    "        \n",
    "        \n",
    "# Write all the info into the file\n",
    "\n",
    "filename = str(user_input_filename_entry) + '.csv'\n",
    "file = open(filename, 'w')\n",
    "file.write('Title,Name,Phone Number, Link\\n')\n",
    "\n",
    "for title, name, phone_number, link in zip(title_ad_for_all_pages, name_for_all_pages, phone_number_for_all_pages,ad_links_to_be_kept):\n",
    "    file.write(title.replace(',', '|') + ',' + name.replace(',', '|') + ',' + phone_number + ',' + link + '\\n')\n",
    "\n",
    "    file.close()\n",
    "    driver.quit()\n",
    "\n",
    "    return True\n",
    "        \n",
    "         \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'return' outside function (<ipython-input-7-d4d4fbe95b76>, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-7-d4d4fbe95b76>\"\u001b[1;36m, line \u001b[1;32m38\u001b[0m\n\u001b[1;33m    return name_for_all_pages, phone_numbers_for_all_pages, links_to_be_removed, title_names_for_all_pages\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'return' outside function\n"
     ]
    }
   ],
   "source": [
    "# Open all the connections to the ad detail page\n",
    "\n",
    "for singleUrl in all_urls:\n",
    "    driver.get(singleUrl)\n",
    "\n",
    "    page_html_ad_detail = urlopen(singleUrl)\n",
    "    soup_ad_detail = BeautifulSoup(page_html_ad_detail, \"html.parser\")\n",
    "\n",
    "    counts_of_completed += 1\n",
    "    percent_completed = str(round((counts_of_completed / ad_links_count) * 100))\n",
    "    print(str(counts_of_completed) + '/' + str(ad_links_count) + ' ({}%) Completed'.format(percent_completed))\n",
    "\n",
    "     # Retrieval of name and phone number from ad page\n",
    "    try:\n",
    "        driver.execute_script(\"document.getElementById('reply-panel-reveal-btn').click()\")\n",
    "        sleep(2)\n",
    "        phone_number_for_single_ad = remove_falsy(driver.find_elements_by_css_selector('.form-row-label'))\n",
    "\n",
    "        contact_name = soup_ad_detail.find(\"h2\", {\"class\": \"truncate-line space-mbn\"}).text.replace('\\n', '')\n",
    "\n",
    "    except WebDriverException:\n",
    "        # No phone number has been found\n",
    "        links_to_be_removed.append(driver.current_url)\n",
    "        print(\"Skipped!\\n\")\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "\n",
    "        name_for_all_pages.append(contact_name)\n",
    "        title_names_for_all_pages.append(driver.title.split('|')[0].strip())\n",
    "\n",
    "        if phone_number_for_single_ad.startswith(\"07\") or phone_number_for_single_ad.startswith(\"447\"):\n",
    "\n",
    "                    phone_numbers_for_all_pages.append(phone_number_for_single_ad)\n",
    "\n",
    "            ####\n",
    "\n",
    "        return name_for_all_pages, phone_numbers_for_all_pages, links_to_be_removed, title_names_for_all_pages\n",
    "\n",
    "    search_url = RetrieveAdInfo(user_input_search_entry, user_input_location_entry, user_input_num_pages_entry)\n",
    "\n",
    "    urls = search_url.retrieve_multiple_pages()\n",
    "    u_request = []\n",
    "    page_html = []\n",
    "    page_soup = []\n",
    "    ad_links_for_all_pages = []\n",
    "\n",
    "    for url in urls:\n",
    "        u_request.append(urlopen(url))\n",
    "\n",
    "    for a in range(len(u_request)):\n",
    "        page_html.append(u_request[a].read())\n",
    "\n",
    "    # Get page_soup for multiple pages\n",
    "    for b in range(len(page_html)):\n",
    "        page_soup.append(BeautifulSoup(page_html[b], \"html.parser\"))\n",
    "\n",
    "    # Get Ad URL\n",
    "    for c in range(len(page_soup)):\n",
    "        containers_for_all_pages = page_soup[c].findAll(\"a\", {\"class\":\"listing-link\"})\n",
    "        ad_links_for_all_pages.append(search_url.retrieve_ad_url(containers_for_all_pages))\n",
    "\n",
    "    if user_input_num_pages_entry > 1:\n",
    "        ad_links_for_all_pages = multi_to_single_list(ad_links_for_all_pages)\n",
    "    else:\n",
    "        # It is assigned the first element since it has a multi-dimensional array\n",
    "        ad_links_for_all_pages = ad_links_for_all_pages[0]\n",
    "\n",
    "    ad_links_count = len(ad_links_for_all_pages)\n",
    "    print(\"\\n\" + str(ad_links_count), \"Ad(s) have/has been found\\n\")\n",
    "\n",
    "    name_for_all_pages, phone_number_for_all_pages, links_to_be_removed, \\\n",
    "        title_ad_for_all_pages = get_ad_details(ad_links_for_all_pages)\n",
    "\n",
    "    # Remove links that are not in list: links_to_be_removed\n",
    "\n",
    "    ad_links_to_be_kept = []\n",
    "    for item in ad_links_for_all_pages:\n",
    "        if item not in links_to_be_removed:\n",
    "            ad_links_to_be_kept.append(item)\n",
    "\n",
    "    # Write all the info into the file\n",
    "\n",
    "    filename = str(user_input_filename_entry) + '.csv'\n",
    "    file = open(filename, 'w')\n",
    "    file.write('Title,Name,Phone Number, Link\\n')\n",
    "\n",
    "    for title, name, phone_number, link in zip(title_ad_for_all_pages, name_for_all_pages, phone_number_for_all_pages,\n",
    "                                               ad_links_to_be_kept):\n",
    "\n",
    "            file.write(title.replace(',', '|') + ',' + name.replace(',', '|') + ',' + phone_number + ',' + link + '\\n')\n",
    "\n",
    "    file.close()\n",
    "    driver.quit()\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
